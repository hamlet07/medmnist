{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from functions import *  # functions used in project\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['tissuemnist', 'retinamnist', 'pneumoniamnist', 'pathmnist', 'organsmnist', 'organcmnist', 'organamnist', 'octmnist', 'dermamnist', 'breastmnist', 'bloodmnist']\n",
    "task = tasks[6]\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload images and resize to 32x32 (28x28 originally)\n",
    "npz_path = Path('/Users/mateusz.maj/Downloads/data_2/', task+'.npz')\n",
    "(train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = load_npz_data(npz_path, resize = True)\n",
    "\n",
    "print('Size of training set:', train_images.shape[0])\n",
    "print('Size of validation set:', val_images.shape[0])\n",
    "print('Size of test set:', test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of examples \n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "for i in range(3):\n",
    "    n = random.randint(0,len(train_images))\n",
    "    img_tensor = np.expand_dims(train_images[n], axis=0)\n",
    "    axes[i].imshow(img_tensor[0])\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Image {n}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of lables in training set\n",
    "for k,v in sorted(Counter(train_labels.ravel()).items()):\n",
    "    print(k, np.round(v/len(train_labels),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of data to Tensorflow processes\n",
    "\n",
    "NUM_CLASSES = max(Counter(train_labels.ravel())) + 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "if NUM_CLASSES > 2:\n",
    "    print('Categorical classification - ', NUM_CLASSES)   \n",
    "else:\n",
    "    print('Binary classification')\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, train_dataset_sub = create_tf_datasets(train_images, train_labels, val_images, val_labels, test_images, test_labels, NUM_CLASSES, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tuning\n",
    "tuner = kt.BayesianOptimization(\n",
    "    lambda hp: build_model(hp, NUM_CLASSES),\n",
    "    objective=kt.Objective('val_weighted_f1_score', direction=\"max\"), \n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory=Path('tuning', task + '/bayesian_tuning_results'),\n",
    "    project_name='vgg16_medical_bayesian',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_dataset_sub,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Best Hyperparameters: \\n\"\n",
    "      f\"Dense Units: {best_hps.get('units')}\\n\"\n",
    "      f\"Dropout Rate: {best_hps.get('dropout')}\\n\"\n",
    "      f\"Optimizer: {best_hps.get('optimizer')}\\n\"\n",
    "      f\"Learning Rate: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath= Path('medicine', task,'best_model.weights.h5'),  # Path to save the best model\n",
    "    monitor='val_weighted_f1_score',    # Metric to monitor (validation accuracy)\n",
    "    mode = 'max',\n",
    "    save_best_only=True,       # Only save when val_accuracy improves\n",
    "    save_weights_only=True,    # Save only the weights, not the entire model (for lighter files)\n",
    "    verbose=1                  # To display when the model is saved\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint_callback, early_stopping],  # Includes the checkpoint callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['weighted_f1_score']\n",
    "val_acc = history.history['val_weighted_f1_score']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = best_model.evaluate(test_dataset, verbose=1)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(test_dataset, verbose = 1)\n",
    "if NUM_CLASSES > 2:\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "else:\n",
    "    predicted_class_indices = np.where(pred>0.5,1,0).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pred, bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {0:0.1f}%\".format(accuracy_score(test_labels.ravel(), predicted_class_indices)*100))\n",
    "print('\\n---Confusion matrix---')\n",
    "print(confusion_matrix(test_labels.ravel(),predicted_class_indices))\n",
    "print('\\n---Classification report---')\n",
    "print(classification_report(test_labels.ravel(), predicted_class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"task_name\": task,\n",
    "    \"label\": predicted_class_indices\n",
    "})\n",
    "results.index.name = \"id_image_in_task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"classification/{task}\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "file_path = f\"{directory}/results.csv\"\n",
    "\n",
    "results.to_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transaction-prediction-u7MsMesz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
